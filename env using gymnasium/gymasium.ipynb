{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fd1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import Box2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a6ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== classic_control =====\n",
      "Acrobot-v1             CartPole-v0            CartPole-v1\n",
      "MountainCar-v0         MountainCarContinuous-v0 Pendulum-v1\n",
      "===== phys2d =====\n",
      "phys2d/CartPole-v0     phys2d/CartPole-v1     phys2d/Pendulum-v0\n",
      "===== box2d =====\n",
      "BipedalWalker-v3       BipedalWalkerHardcore-v3 CarRacing-v3\n",
      "LunarLander-v3         LunarLanderContinuous-v3\n",
      "===== toy_text =====\n",
      "Blackjack-v1           CliffWalking-v1        CliffWalkingSlippery-v1\n",
      "FrozenLake-v1          FrozenLake8x8-v1       Taxi-v3\n",
      "===== tabular =====\n",
      "tabular/Blackjack-v0   tabular/CliffWalking-v0\n",
      "===== None =====\n",
      "Ant-v2                 Ant-v3                 GymV21Environment-v0\n",
      "GymV26Environment-v0   HalfCheetah-v2         HalfCheetah-v3\n",
      "Hopper-v2              Hopper-v3              Humanoid-v2\n",
      "Humanoid-v3            HumanoidStandup-v2     InvertedDoublePendulum-v2\n",
      "InvertedPendulum-v2    Pusher-v2              Reacher-v2\n",
      "Swimmer-v2             Swimmer-v3             Walker2d-v2\n",
      "Walker2d-v3\n",
      "===== mujoco =====\n",
      "Ant-v4                 Ant-v5                 HalfCheetah-v4\n",
      "HalfCheetah-v5         Hopper-v4              Hopper-v5\n",
      "Humanoid-v4            Humanoid-v5            HumanoidStandup-v4\n",
      "HumanoidStandup-v5     InvertedDoublePendulum-v4 InvertedDoublePendulum-v5\n",
      "InvertedPendulum-v4    InvertedPendulum-v5    Pusher-v4\n",
      "Pusher-v5              Reacher-v4             Reacher-v5\n",
      "Swimmer-v4             Swimmer-v5             Walker2d-v4\n",
      "Walker2d-v5\n"
     ]
    }
   ],
   "source": [
    "gym.pprint_registry()  # Print all registered environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f1921",
   "metadata": {},
   "source": [
    "CARTPOLE ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d813bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a3e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment to start a new episode\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b376945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting observation: [-0.04977376 -0.02828283 -0.0048169   0.03879701]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting observation: {observation}\")\n",
    "# # [cart_position, cart_velocity, pole_angle, pole_angular_velocity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9ee7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_over = False\n",
    "total_reward = 0\n",
    "\n",
    "while not episode_over:\n",
    "    # Choose an action: 0 = push cart left, 1 = push cart right\n",
    "    action = env.action_space.sample()  # Random action for now - real agents will be smarter!\n",
    "\n",
    "    # Take the action and see what happens\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9f5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished! Total reward: 26.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode finished! Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18627875",
   "metadata": {},
   "source": [
    "## LUNAR LANDER ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad73b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
